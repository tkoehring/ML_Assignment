{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eaf81d-a14c-4cd0-82f5-913b673fe031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments, get_scheduler\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31fae8d-8ee0-418e-a222-a1015e9c0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing distilbert due to its smaller size while maintaining high accuracy\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "transformer_backbone = AutoModel.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821494fa-b4c8-4454-abe9-ad962a818524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom NLP Model class\n",
    "# Contains multiple heads for different learning tasks with a forward pass to run them both\n",
    "\n",
    "class CustomModelNLP(nn.Module):\n",
    "    def __init__(self, transformer_backbone):\n",
    "        super(CustomModelNLP, self).__init__()\n",
    "        # Number of labels for sentence classification\n",
    "        self.nLabels = 6\n",
    "        #Number of labels for sentiment analysis\n",
    "        self.nSentinment = 2\n",
    "\n",
    "        #Model Layers\n",
    "        self.transformer_backbone = transformer_backbone\n",
    "        self.classifier = nn.Linear(transformer_backbone.config.hidden_size, self.nLabels)\n",
    "        self.sentiment = nn.Linear(transformer_backbone.config.hidden_size, self.nSentinment)\n",
    "\n",
    "        # Freeze transformer\n",
    "        for param in self.transformer_backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, task_id):\n",
    "        out = self.transformer_backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embedding = out.last_hidden_state[:, 0, :]\n",
    "\n",
    "        if task_id == 0:\n",
    "            out = self.classifier(embedding)\n",
    "        elif task_id == 1:\n",
    "            out = self.sentiment(embedding)\n",
    "        else:\n",
    "            assert False, 'Bad Task ID'\n",
    "        \n",
    "        return out\n",
    "\n",
    "#Tokenization function\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "customModel = CustomModelNLP(transformer_backbone)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c19081-f81c-4f9c-be3f-5086361df501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and get embeddings\n",
    "sentences = [\"The old clock tower chimed, echoing through the quiet city streets.\", \n",
    "             \"A vibrant tapestry of colors adorned the window, catching the afternoon sunlight.\", \n",
    "             \"The children giggled as the playful puppy chased its tail in the park.\"]\n",
    "task_ids = [0,1,0]\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"Sample tokenization output. Tensor output hidden due to length\")\n",
    "print(\"=\"*40)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokenized_sentence = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    output = transformer_backbone(input_ids=tokenized_sentence.input_ids, attention_mask=tokenized_sentence.attention_mask)\n",
    "    embedding = output.last_hidden_state[:, 0, :] \n",
    "    print(embedding.shape)\n",
    "#print(embedding)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"=\"*40)\n",
    "print(\"Sample model output depending on task id\")\n",
    "print(\"=\"*40)\n",
    "print(\"\\n\")\n",
    "\n",
    "for sentence, task_id in zip(sentences, task_ids):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    print(inputs)\n",
    "    with torch.no_grad():\n",
    "        output = customModel(input_ids = inputs.input_ids, attention_mask = inputs.attention_mask, task_id = task_id)\n",
    "        \n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32683187-e72b-4b5d-a2cc-670c5e8ea0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data & Tokenize\n",
    "emotion_data_split = load_dataset(\"dair-ai/emotion\", \"split\")\n",
    "sentiment_data = load_dataset(\"gxb912/large-twitter-tweets-sentiment\")\n",
    "tokenized_emotion_data = emotion_data_split.map(tokenize_function, batched=True)\n",
    "tokenized_sentiment_data = sentiment_data.map(tokenize_function, batched=True)\n",
    "print(tokenized_emotion_data[\"train\"].shape)\n",
    "print(tokenized_sentiment_data[\"train\"].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fbd52d-532e-43a8-be5b-7e43d5d7194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data into a dataloader object\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "emotion_train_dataloader = DataLoader(\n",
    "    tokenized_emotion_data['train'].remove_columns([\"text\"]), shuffle = True, batch_size = 32, collate_fn = data_collator\n",
    ")\n",
    "emotion_validation_dataloader = DataLoader(\n",
    "    tokenized_emotion_data['validation'].remove_columns([\"text\"]), shuffle = True, batch_size = 32, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "sentiment_train_dataloader = DataLoader(\n",
    "    tokenized_sentiment_data['train'].remove_columns([\"text\"]), shuffle = True, batch_size = 32, collate_fn = data_collator\n",
    ")\n",
    "\n",
    "sentiment_validation_dataloader = DataLoader(\n",
    "    tokenized_sentiment_data['test'].remove_columns([\"text\"]), shuffle = True, batch_size = 32, collate_fn = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b8b86-d07c-4de3-93f6-c270d240ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop parameters\n",
    "learning_rate = 1e-6\n",
    "epochs = 5\n",
    "steps = epochs * len(emotion_train_dataloader)\n",
    "optimizer = torch.optim.Adam(customModel.parameters(), lr = learning_rate)\n",
    "\n",
    "# Loss & Metric Functions\n",
    "emotion_loss_fn = nn.CrossEntropyLoss()\n",
    "sentiment_loss_fn = nn.CrossEntropyLoss()\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d20a3b-cce8-47c5-a843-4cbd8e8505c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cuda device if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "customModel = customModel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889a18b-be25-4b00-9290-27e1a839f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress bars\n",
    "progress_bar_train = tqdm(range(steps))\n",
    "progress_bar_eval = tqdm(range(epochs * len(emotion_validation_dataloader) ))\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    # Zip both data sets\n",
    "    train_zip_dl = zip(emotion_train_dataloader, sentiment_train_dataloader)\n",
    "    validation_zip_dl = zip(emotion_validation_dataloader, sentiment_validation_dataloader)\n",
    "\n",
    "    # Train\n",
    "    customModel.train()\n",
    "    for emotion_batch, sentiment_batch in train_zip_dl:\n",
    "        emotion_batch.to(device)\n",
    "        sentiment_batch.to(device)\n",
    "        emotions_predicitons = customModel(emotion_batch['input_ids'], emotion_batch['attention_mask'], task_id = 0)\n",
    "        emotions_loss = emotion_loss_fn(emotions_predicitons, emotion_batch['labels'])\n",
    "        sentiment_predicitons = customModel(sentiment_batch['input_ids'], sentiment_batch['attention_mask'], task_id = 1)\n",
    "        sentiment_loss = sentiment_loss_fn(torch.argmax(sentiment_predicitons, dim = -1).float(), sentiment_batch['sentiment'].float())\n",
    "        loss = emotions_loss + sentiment_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "    # Evaluate\n",
    "    customModel.eval()\n",
    "    for emotion_batch, sentiment_batch in validation_zip_dl:\n",
    "        emotion_batch.to(device)\n",
    "        sentiment_batch.to(device)\n",
    "        emotions_predicitons = customModel(emotion_batch['input_ids'], emotion_batch['attention_mask'], task_id = 0)\n",
    "        sentiment_predicitons = customModel(sentiment_batch['input_ids'], sentiment_batch['attention_mask'], task_id = 1)\n",
    "\n",
    "        # Add predictions to metric\n",
    "        metric.add_batch(predictions = torch.argmax(emotions_predicitons, dim=-1), references = emotion_batch['labels'])   \n",
    "        metric.add_batch(predictions = torch.argmax(sentiment_predicitons, dim=-1), references = sentiment_batch['sentiment']) \n",
    "        progress_bar_eval.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe4f55-7835-426b-a390-0bdffc50c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metric.compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
